I limiti espressi nel capitolo precedente in termini di efficienza energetica hanno, nel tempo, imposto la tendenza dell'industria produttrice di processori la tendenza a progettare sistemi multi/many core invece che singoli processori ad alte performance. 
I sistemi \textbf{multicore} sono composti da 2 fino 8 nuclei di fascia medio-alta, mentre i sistemi \textbf{manycore} sono composti da 8 fino a 16 nuclei di fascia medio-bassa. Nelle architetture manycore l'enfasi è posta sulle \textit{interconnesioni} e sulle \textit{architetture di memoria}. Gli accessi in memoria possono \textbf{uniformi} (UMA), come ad esempio in RAM dove il tempo in cui viene effettuato l'accesso al dato non dipende dal punto in cui vi si accede, oppure \textbf{non uniformi} (NUMA), durante il quale il tempo di accesso ad uno spazio di indirizzamento logicamente unico dipende però dal punto in cui si accede. 

\noindent Gli accessi in memoria possono essere indipendenti gli uni dagli altri, e può succedere che il processore o la Load/Store unit invertano, per massimizzare l'efficienza, l'ordine di queste operazioni. In particolare queste operazioni possono essere invertite nel caso operino su indirizzi diversi, in modo da non generare interferenze. Questo funziona su un singolo core, mentre nelle architetture manycore che sfruttando la gerarchizzazione della memoria possono verificarsi delle complicazioni. Lo scheduling dinamico, a livello core, può cambiare l'ordine di operazioni di Load/Store che sono viste indipendenti \textit{localmente}, mentre potrebbero non esserlo a globalmente. Un esempio di problema di coerenza potrebbe essere il caso di due processi, produttore e consumatore, in esecuzione su due core diversi, che usano la primitiva forma di sincronizzazione di set/lettura di un flag condiviso. Il produttore performa in memoria le operazioni di scrittura dato e scrittura flag, mentre il consumatore performa in memoria le operazioni di lettura flag e lettura dato; se l'ordine di una di queste operazioni fosse invertito, si violerebbe la consistenza della memoria, e ciò condurrebbe ad una violazione del principio di causa/effetto.  

\noindent Per quanto riguarda l'unità di Load/Store, abbiamo visto che è possibile applicare la tecnica del \textit{bypass locale}, che permette ad operazioni di store di alimentare operazioni di load conseguenti a livello hardware. \uppercase{è} possibile applicare tecniche come \textbf{Address Alias Prediction}, tramite la quale predire se due operazioni con indirizzi effettivi ancora non risolti possano andare in conflitto, e riordinare speculativamente le operazioni, o tecniche come il \textbf{Memory coalescing}, tramite il quale compattare più operazioni di Load/Store in una singola operazioni fisica, accedendo in una volta sola a più blocchi di memoria. 


\noindent Un'ulteriore fonte di complessità deriva dal modello architetturale di memorie distribuite ed interconnesse. L'interconnessione avviene tramite protocolli bus più o meno complessi: \textbf{bus atomici} consentono la soluzione più semplice, rispettando l'ordine stretto delle transazioni e non consentendo la sovrapposizione; \textbf{bus pipelined} consentono la sovrapposizione delle transazioni (\textit{richieste}), garantendo però che le \textit{risposte} arrivino nell'ordine giusto; \textit{bus split-transaction}, consentono di invertire l'ordine delle risposte, mantenendo però l'informazione riguardo l'ID della richiesta. Le complicazioni possono aumentare nel caso di interconnessioni più sofisticate (\textit{networks on chip}).
